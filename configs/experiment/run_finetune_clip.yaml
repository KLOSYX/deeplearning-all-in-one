# @package _global_

defaults:
  - override /datamodule: multi_modal_data.yaml
  - override /model: fine_tune_clip_model.yaml
  - override /callbacks: default.yaml
  - override /trainer: deepspeed.yaml
  - override /logger: wandb.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["finetune", "multimodal", "clip"]
monitor: val/loss

test: false

seed: 42

trainer:
  min_epochs: 0
  max_epochs: 20
  gradient_clip_val: 0
  devices: 4,5,6,7
  log_every_n_steps: 100
  precision: 16
  val_check_interval: 1000

logger:
  wandb:
    project: finetune_clip
    tags: ${tags}

callbacks:
  model_checkpoint:
    monitor: ${monitor}
    mode: min
  early_stopping:
    monitor: ${monitor}
    mode: min
    patience: 3

datamodule:
  batch_size: 64
