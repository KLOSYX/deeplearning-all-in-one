_target_: src.models.bert_for_sequence_classification.BertSequenceClassification

num_classes: 10
bert_name: hfl/chinese-roberta-wwm-ext
dropout_prob: 0.1
num_warmup_steps: 400
label_smooth: False
focal_loss: False
learning_rate: 0.0001
weight_decay: 0.05
pooler: average
