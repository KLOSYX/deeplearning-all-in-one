# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: sim_bert_data.yaml
  - override /model: sim_bert_model.yaml
  - override /callbacks: default.yaml
  - override /trainer: deepspeed.yaml
  - override /logger: wandb.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["simbert", "pretrain"]
monitor: val/loss
bert_name_or_path: hfl/chinese-roberta-wwm-ext

test: False

seed: 42

trainer:
  min_epochs: 0
  max_epochs: 20
  gradient_clip_val: 1.0
  devices: 1,2,3,4
  precision: 32
  log_every_n_steps: 50

logger:
  wandb:
    project: pretrain_simbert
    tags: ${tags}

callbacks:
  model_checkpoint:
    monitor: ${monitor}
    mode: min
  early_stopping:
    monitor: ${monitor}
    mode: min
    patience: 3

model:
  lr: 0.0001
  bert_name: ${bert_name_or_path}
  label_smoothing: 0.1

datamodule:
  tokenizer_name: ${bert_name_or_path}
  val_ratio: 0.1
