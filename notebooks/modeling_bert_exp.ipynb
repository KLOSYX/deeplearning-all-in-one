{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "\n",
    "from src.models.components.bert.modeling_bert import (\n",
    "    BertModel,\n",
    "    BertOnlyMLMHead,\n",
    "    BertPooler,\n",
    "    BertPreTrainedModel,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\", cache_dir=\"~/.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"bert-base-chinese\", cache_dir=\"~/.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"[CLS]hello, my dog is cute.[SEP]hi, this is my lovely dog.[SEP][PAD][PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    [\n",
    "        (\"hello, my dog is cute.\", \"hi, this is my lovely dog.\"),\n",
    "        (\"good luck to you.\", \"hope you good luck.\"),\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"do_not_pad\",\n",
    "    truncation=True,\n",
    "    max_length=22,\n",
    "    return_special_tokens_mask=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs.input_ids\n",
    "sep_id = tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (input_ids[0] == sep_id).nonzero()[0][0].item()\n",
    "(input_ids[0] == sep_id).nonzero()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tril(torch.ones(5, 5), diagonal=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simbert_mask(input_ids: torch.Tensor, sep_token_id: int) -> torch.Tensor:\n",
    "    sequence_length = input_ids.size(-1)\n",
    "    attention_masks = []\n",
    "    for sequence_ids in input_ids:\n",
    "        first_sep = (sequence_ids == sep_id).nonzero()[0][-1].item()\n",
    "        last_sep = (sequence_ids == sep_id).nonzero()[-1][-1].item()\n",
    "        attention_mask = torch.zeros((sequence_length, sequence_length), dtype=torch.long)\n",
    "        attention_mask[: last_sep + 1, : first_sep + 1] = 1\n",
    "        attention_mask[first_sep + 1 : last_sep + 1, first_sep + 1 : last_sep + 1] = torch.tril(\n",
    "            torch.ones(last_sep - first_sep, last_sep - first_sep), diagonal=0\n",
    "        )\n",
    "        attention_masks.append(attention_mask.unsqueeze(0))\n",
    "    return torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_ids[0] == sep_id).nonzero()[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_pos = (input_ids == sep_id).nonzero()[:, 1, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simbert_labels(\n",
    "    input_ids: torch.Tensor, pad_token_id: torch.Tensor, sep_token_id: int = 102\n",
    ") -> torch.Tensor:\n",
    "    labels = input_ids.clone()\n",
    "    for label in labels:\n",
    "        first_sep = (label == sep_token_id).nonzero()[0][0].item()\n",
    "        label[: first_sep + 1] = -100\n",
    "    labels[labels == pad_token_id] = -100\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.input_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_simbert_mask(inputs.input_ids, tokenizer.sep_token_id)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(\n",
    "    get_simbert_labels(inputs.input_ids, tokenizer.pad_token_id, tokenizer.sep_token_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimBertModel(BertPreTrainedModel):\n",
    "\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        assert not config.is_decoder, \"Model is not a decoder but is being used as one\"\n",
    "        assert hasattr(config, \"vector_dim\"), \"Vector dim is not defined\"\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "        self.projector = torch.nn.Linear(config.hidden_size, config.vector_dim)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "        self.tie_weights()\n",
    "\n",
    "    def tie_weights(self):\n",
    "        self._tie_or_clone_weights(\n",
    "            self.cls.predictions.decoder, self.bert.embeddings.word_embeddings\n",
    "        )\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.cls.predictions.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.cls.predictions.decoder = new_embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.Tensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], CausalLMOutputWithCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\n",
    "            `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are\n",
    "            ignored (masked), the loss is only computed for the tokens with labels n `[0, ..., config.vocab_size]`\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        if labels is not None:\n",
    "            use_cache = False\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.cls(sequence_output)\n",
    "\n",
    "        lm_loss = None\n",
    "        if labels is not None:\n",
    "            # we are doing next-token prediction; shift prediction scores and input ids by one\n",
    "            shifted_prediction_scores = prediction_scores[:, :-1, :].contiguous()\n",
    "            labels = labels[:, 1:].contiguous()\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            lm_loss = loss_fct(\n",
    "                shifted_prediction_scores.view(-1, self.config.vocab_size),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((lm_loss,) + output) if lm_loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithCrossAttentions(\n",
    "            loss=lm_loss,\n",
    "            logits=prediction_scores,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "    def forward_vector(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], CausalLMOutputWithCrossAttentions]:\n",
    "        forward_output = self.forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            labels=labels,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        vector_output = self.projector(\n",
    "            forward_output.hidden_states[-1][:, 0, :]\n",
    "        )  # (N, vector_dim)\n",
    "        return forward_output, vector_output\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], CausalLMOutputWithCrossAttentions]:\n",
    "        forward_output = self.forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            labels=labels,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        vector_output = self.projector(\n",
    "            forward_output.hidden_states[-1][:, 0, :]\n",
    "        )  # (N, vector_dim)\n",
    "        return vector_output\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self, input_ids, past=None, attention_mask=None, **model_kwargs\n",
    "    ):\n",
    "        input_shape = input_ids.shape\n",
    "        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly\n",
    "        if attention_mask is None:\n",
    "            attention_mask = input_ids.new_ones(input_shape)\n",
    "\n",
    "        # cut decoder_input_ids if past is used\n",
    "        if past is not None:\n",
    "            input_ids = input_ids[:, -1:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"past_key_values\": past,\n",
    "        }\n",
    "\n",
    "    def _reorder_cache(self, past, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past:\n",
    "            reordered_past += (\n",
    "                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past),\n",
    "            )\n",
    "        return reordered_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vector_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimBertModel.from_pretrained(\"bert-base-chinese\", config=config, cache_dir=\"~/.cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=get_simbert_mask(inputs.input_ids, tokenizer.sep_token_id),\n",
    "    labels=get_simbert_labels(inputs.input_ids, tokenizer.pad_token_id, tokenizer.sep_token_id),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(\n",
    "    model.generate(\n",
    "        tokenizer([\"你好世界\"], return_tensors=\"pt\").input_ids, do_sample=True, max_length=20\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_vector(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=get_simbert_mask(inputs.input_ids, tokenizer.sep_token_id),\n",
    "    labels=get_simbert_labels(inputs.input_ids, tokenizer.pad_token_id, tokenizer.sep_token_id),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
